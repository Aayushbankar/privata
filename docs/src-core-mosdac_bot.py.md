# src/core/mosdac_bot.py - MOSDAC AI Help Bot Master Control

## üìã Overview
**File**: `src/core/mosdac_bot.py`  
**Location**: `src/core/`  
**Purpose**: Master control file that orchestrates all MOSDAC AI Help Bot components  
**Type**: Core orchestration module  
**Dependencies**: `asyncio`, `json`, `os`, `subprocess`, `sys`, `pathlib`, `datetime`, `typing`, `logging`

## üéØ Purpose & Functionality

The `mosdac_bot.py` file is the heart of the MOSDAC AI Help Bot system. It serves as the master controller that:
- Orchestrates all existing components (scraper, ingestion, chat)
- Provides a unified control interface
- Manages the complete workflow from data scraping to AI chat
- Handles component availability checking and error management
- Provides a user-friendly menu system for all operations

## üîß Development Journey

### Evolution of the Master Control

#### Phase 1: Initial Implementation
**Date**: Early development  
**Approach**: Embedded all logic directly in the bot class
**Issues Encountered**:
- Code became too large and complex
- Difficult to maintain and debug
- Mixed concerns (UI, business logic, data management)

#### Phase 2: Modular Approach
**Date**: Mid-development  
**Approach**: Split into separate modules but kept complex orchestration
**Issues Encountered**:
- Import path problems after folder restructuring
- Async event loop conflicts
- Component detection failures

#### Phase 3: Current Implementation
**Date**: Final implementation  
**Approach**: Clean orchestration that delegates to existing modules
**Success Factors**:
- Proper path management
- Async/await pattern
- Component availability checking
- Error handling and recovery

### Key Design Decisions

#### Why Orchestration Instead of Embedded Logic?
During development, we tried embedding all logic directly in the bot class, but this led to:
- **Maintenance Nightmare**: 1000+ lines of mixed concerns
- **Testing Difficulties**: Hard to test individual components
- **Import Issues**: Complex dependencies and circular imports
- **User Experience**: Poor error handling and unclear feedback

**The Solution**: Create a clean orchestration layer that:
- Uses existing, tested components
- Provides clear error messages
- Handles component availability gracefully
- Maintains separation of concerns

## üìù Code Analysis

### Class Structure

#### MOSDACBot Class
```python
class MOSDACBot:
    """Master control for MOSDAC AI Help Bot using existing components"""
```

**Design Philosophy**: The class follows the Facade pattern, providing a simple interface to complex subsystems.

### Initialization

#### Constructor
```python
def __init__(self):
    # Get the project root directory
    project_root = Path(__file__).parent.parent.parent
    
    # Configuration
    self.crawl_output_dir = project_root / "data/scraped/mosdac_complete_data"
    self.chroma_dir = project_root / "data/vector_db/chroma_db"
    self.llm_available = False
    
    # Check if components are available
    self.check_components()
```

**Development Notes**:
- **Path Resolution**: Uses `Path(__file__).parent.parent.parent` to get project root
- **Error Encountered**: Initially used relative paths, causing issues when running from different directories
- **Solution**: Use absolute paths based on file location

**Error Encountered**: `FileNotFoundError` when accessing data directories
**Solution**: Create directories if they don't exist and use absolute paths

### Component Management

#### Component Checking
```python
def check_components(self):
    """Check if all required components are available"""
    # Get the project root directory
    project_root = Path(__file__).parent.parent.parent
    
    components = {
        "crawler": (project_root / "src/scrapers/crawl4ai_mosdac.py").exists(),
        "ingest": (project_root / "src/ingestion/ingest.py").exists(),
        "chat": (project_root / "src/chat/chat.py").exists(),
        "config": (project_root / "src/core/config.py").exists(),
        "llm_loader": (project_root / "src/models/llm_loader.py").exists()
    }
```

**Development Journey**:
1. **Initial Approach**: Hard-coded file paths
2. **Problem**: Paths broke after folder restructuring
3. **Solution**: Dynamic path resolution using project root

**Error Encountered**: `FileNotFoundError` after folder restructuring
**Solution**: Updated all paths to use `project_root` variable

### Data Scraping

#### Scrape Data Method
```python
async def scrape_data(self):
    """Scrape data using existing comprehensive scraper"""
    logger.info("üîç Starting comprehensive data scraping...")
    
    try:
        # Import and run the comprehensive scraper
        import sys
        sys.path.append('src/scrapers')
        from comprehensive_mosdac_scraper import ComprehensiveMOSDACScraper
        
        # Use comprehensive scraper with correct output directory
        scraper = ComprehensiveMOSDACScraper(output_dir=str(self.crawl_output_dir))
        stats = await scraper.run_comprehensive_scraping()
```

**Development Evolution**:
1. **First Version**: Used subprocess to call external scripts
2. **Problem**: Error handling was difficult, no access to return values
3. **Current Version**: Direct import and method calls

**Error Encountered**: `ModuleNotFoundError: No module named 'comprehensive_mosdac_scraper'`
**Solution**: Added `sys.path.append('src/scrapers')` before import

**Error Encountered**: Scraper storing data in wrong location
**Solution**: Pass `output_dir=str(self.crawl_output_dir)` to scraper constructor

### Data Ingestion

#### Ingest Data Method
```python
def ingest_data(self):
    """Ingest data using existing ingestion pipeline"""
    logger.info("üì• Starting data ingestion...")
    
    try:
        # Import and run the ingestion pipeline
        import sys
        sys.path.append('src/ingestion')
        from ingest import ModernIngestionPipeline
        
        # Create and run the pipeline
        pipeline = ModernIngestionPipeline()
        result = pipeline.run_ingestion(str(self.crawl_output_dir))
```

**Development Journey**:
1. **Initial Approach**: Tried to use `advanced_rag_ingestion.py`
2. **Problem**: Heavy dependencies (numpy, sklearn) caused installation issues
3. **Solution**: Reverted to existing `ingest.py` with `ModernIngestionPipeline`

**Error Encountered**: `ModuleNotFoundError: No module named 'numpy'`
**Solution**: Used existing `ingest.py` instead of advanced version

**Error Encountered**: `run_modern_ingestion() takes 1 positional argument but 2 were given`
**Solution**: Used `ModernIngestionPipeline` class instead of function

### Chat System

#### Start Chat Method
```python
def start_chat(self):
    """Start the existing chat system"""
    logger.info("üí¨ Starting chat system...")
    
    if not self.llm_available:
        print("‚ùå LLM not available. Please check your configuration:")
        print("   ‚Ä¢ For API mode: Set GEMINI_API_KEY environment variable")
        print("   ‚Ä¢ For Ollama mode: Set LLM_MODE=ollama and ensure Ollama is running")
        return
    
    try:
        # Import and start the existing chat system
        import sys
        import importlib.util
        spec = importlib.util.spec_from_file_location("chat", self.crawl_output_dir.parent.parent.parent / "src/chat/chat.py")
        chat_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(chat_module)
        chat_module.start_modern_chat()
```

**Development Evolution**:
1. **First Version**: Simple import and call
2. **Problem**: Import issues after folder restructuring
3. **Current Version**: Dynamic module loading using `importlib.util`

**Error Encountered**: `cannot import name 'start_modern_chat' from 'chat'`
**Solution**: Used `importlib.util.spec_from_file_location` for dynamic loading

### Data Status Checking

#### Get Data Status Method
```python
def get_data_status(self):
    """Get current data status"""
    status = {
        "scraped_data": {
            "pages_count": 0,
            "total_content_length": 0,
            "last_scraped": None
        },
        "vector_db": {
            "collection_exists": False,
            "documents_count": 0
        },
        "llm": {
            "mode": "unknown",
            "api_key_set": False,
            "available": False
        },
        "components": {
            "crawler": False,
            "ingest": False,
            "chat": False
        }
    }
```

**Development Journey**:
1. **Initial Version**: Simple file existence checks
2. **Problem**: No detailed information about data quality
3. **Current Version**: Comprehensive status with statistics

**Error Encountered**: Looking for wrong summary file (`crawling_summary.json` vs `comprehensive_index.json`)
**Solution**: Check for both file types and parse accordingly

### Data Management

#### Remove Data Method
```python
def remove_data(self):
    """Remove all scraped data and vector database"""
    logger.info("üóëÔ∏è Removing all data...")
    
    # Remove scraped data
    if self.crawl_output_dir.exists():
        import shutil
        shutil.rmtree(self.crawl_output_dir)
        logger.info("‚úÖ Removed scraped data")
    
    # Remove vector database
    if self.chroma_dir.exists():
        import shutil
        shutil.rmtree(self.chroma_dir)
        logger.info("‚úÖ Removed vector database")
```

**Development Notes**:
- **Safety**: Only removes data directories, not source code
- **Logging**: Provides clear feedback on what was removed
- **Recovery**: Recreates directories for future use

### Workflow Management

#### Complete Workflow
```python
async def scrape_and_ingest(self):
    """Complete workflow: scrape and ingest data"""
    logger.info("üöÄ Starting complete workflow: scrape + ingest")
    
    # Step 1: Scrape data
    scrape_success = await self.scrape_data()
    if not scrape_success:
        logger.error("‚ùå Scraping failed, aborting workflow")
        return False
    
    # Step 2: Ingest data
    ingest_success = self.ingest_data()
    if not ingest_success:
        logger.error("‚ùå Ingestion failed")
        return False
    
    logger.info("‚úÖ Complete workflow finished successfully!")
    return True
```

**Development Evolution**:
1. **First Version**: Synchronous workflow
2. **Problem**: Async event loop conflicts
3. **Current Version**: Proper async/await pattern

**Error Encountered**: `RuntimeError: asyncio.run() cannot be called from a running event loop`
**Solution**: Made method async and used `await` instead of `asyncio.run()`

### Main Function

#### Async Main Function
```python
async def main():
    """Main function"""
    bot = MOSDACBot()
    
    while True:
        show_menu()
        choice = input("Select an option (1-8): ").strip()
        
        if choice == "1":
            print("\nüîç Starting data scraping...")
            success = await bot.scrape_data()
            if success:
                print("‚úÖ Data scraping completed successfully!")
            else:
                print("‚ùå Data scraping failed!")
```

**Development Journey**:
1. **Initial Version**: Synchronous main function
2. **Problem**: Couldn't handle async scraping
3. **Current Version**: Async main function with proper await calls

**Error Encountered**: `RuntimeWarning: coroutine 'main' was never awaited`
**Solution**: Made main function async and used `asyncio.run(main())` in entry point

## üöÄ Usage Examples

### Basic Usage
```python
from src.core.mosdac_bot import MOSDACBot

# Create bot instance
bot = MOSDACBot()

# Check status
status = bot.get_data_status()
print(f"Pages scraped: {status['scraped_data']['pages_count']}")

# Scrape data
success = await bot.scrape_data()
if success:
    print("Scraping completed!")
```

### Complete Workflow
```python
# Run complete workflow
success = await bot.scrape_and_ingest()
if success:
    print("Complete workflow finished!")
    
    # Start chat
    bot.start_chat()
```

## üîç Error Handling

### Common Errors and Solutions

#### 1. Component Not Found
**Error**: `FileNotFoundError: [Errno 2] No such file or directory: 'src/scrapers/crawl4ai_mosdac.py'`
**Cause**: Running from wrong directory or missing files
**Solution**: Ensure you're running from project root and all files exist

#### 2. Import Errors
**Error**: `ModuleNotFoundError: No module named 'comprehensive_mosdac_scraper'`
**Cause**: Python path not set correctly
**Solution**: The bot automatically adds paths, but ensure you're running from project root

#### 3. Async Event Loop Errors
**Error**: `RuntimeError: asyncio.run() cannot be called from a running event loop`
**Cause**: Calling async methods from within existing event loop
**Solution**: Use `await` instead of `asyncio.run()` when already in async context

#### 4. LLM Not Available
**Error**: Chat system shows "LLM not available"
**Cause**: Missing API key or Ollama not running
**Solution**: Set `GEMINI_API_KEY` environment variable or start Ollama

## üß™ Testing

### Manual Testing
```bash
# Test component detection
python -c "from src.core.mosdac_bot import MOSDACBot; bot = MOSDACBot(); print(bot.check_components())"

# Test data status
python -c "from src.core.mosdac_bot import MOSDACBot; bot = MOSDACBot(); print(bot.get_data_status())"

# Test complete workflow
python -c "import asyncio; from src.core.mosdac_bot import MOSDACBot; bot = MOSDACBot(); asyncio.run(bot.scrape_and_ingest())"
```

### Automated Testing
The bot is tested by:
1. Verifying all components are detected
2. Testing data status reporting
3. Running complete workflows
4. Checking error handling

## üìä Performance Considerations

### Memory Usage
- **Initialization**: ~10MB (imports and setup)
- **During Scraping**: ~50-100MB (depends on data size)
- **During Ingestion**: ~200-500MB (embedding models)
- **During Chat**: ~100-200MB (loaded models)

### Processing Time
- **Component Check**: ~100ms
- **Data Status**: ~200ms
- **Scraping**: 5-15 minutes (443 URLs)
- **Ingestion**: 3-5 minutes (708 chunks)
- **Chat Startup**: ~10-15 seconds

## üîÆ Future Enhancements

### Planned Features
1. **Configuration Management**: Better config file support
2. **Progress Tracking**: Real-time progress bars for long operations
3. **Error Recovery**: Automatic retry mechanisms
4. **Logging**: Structured logging with different levels
5. **API Mode**: REST API for programmatic access

### Potential Improvements
1. **Parallel Processing**: Concurrent scraping and ingestion
2. **Caching**: Cache component availability checks
3. **Health Monitoring**: Continuous health checks
4. **Metrics**: Performance metrics collection

## üìö Related Files

- `main.py`: Entry point that calls this module
- `src/scrapers/comprehensive_mosdac_scraper.py`: Data scraping component
- `src/ingestion/ingest.py`: Data ingestion component
- `src/chat/chat.py`: Chat system component
- `src/models/llm_loader.py`: LLM management
- `src/core/config.py`: Configuration management

## üêõ Known Issues

### Current Limitations
1. **No Progress Bars**: Long operations don't show progress
2. **Limited Error Recovery**: Some errors require manual intervention
3. **No Configuration Validation**: Invalid configs cause runtime errors
4. **Single-threaded**: Operations run sequentially

### Workarounds
- Use the menu system for step-by-step operations
- Check component availability before running workflows
- Monitor logs for detailed error information
- Use data status check to verify operations

## üìà Development Metrics

### Lines of Code
- **Total**: 414 lines
- **Comments**: 45 lines
- **Functional Code**: 369 lines
- **Complexity**: Medium (orchestration logic)

### Maintenance
- **Last Updated**: 2025-09-13
- **Stability**: High (core functionality stable)
- **Testing**: Manual testing with some automated checks

## üéâ Success Stories

### What Works Well
1. **Unified Interface**: Single point of control for all operations
2. **Error Handling**: Clear error messages and recovery guidance
3. **Component Management**: Automatic detection and availability checking
4. **Workflow Orchestration**: Seamless end-to-end operations

### Lessons Learned
1. **Orchestration vs Implementation**: Keep orchestration separate from implementation
2. **Path Management**: Use absolute paths based on file location
3. **Async Patterns**: Proper async/await usage is crucial
4. **Error Recovery**: Provide clear guidance for error resolution
5. **User Experience**: Clear feedback and status information

---

*This documentation was created as part of the MOSDAC AI Help Bot development process. It serves as both a reference and a development diary, capturing the decisions, errors, and solutions encountered during the creation of this master control module.*
