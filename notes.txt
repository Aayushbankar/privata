────────────────────────────────────────────────────────────
📌 PRIVATA: RAG-Based Private Document Assistant (CLI)
────────────────────────────────────────────────────────────

🔧 STACK OVERVIEW:
- Built in Python 3.13
- CLI-only (modular), no web UI
- Uses Retrieval-Augmented Generation (RAG)
- Local embeddings (HuggingFace), cloud LLM (Gemini 1.5 Flash)

──────────────────────────────────────────────
🧠 CORE WORKFLOW (RAG PIPELINE)
──────────────────────────────────────────────
1. 📁 Ingest documents (.pdf / .txt / .md) via CLI
2. 🧩 Use  loaders to parse file contents
3. ✂️ Chunk text with LangChain’s TextSplitter
4. 📐 Embed chunks using HuggingFace MiniLM
5. 💾 Store vectors locally in ChromaDB
6. 💬 User enters query → embedded → vector similarity search
7. 🔄 Top-K chunks retrieved → prompt constructed
8. 🧠 Sent to Google Gemini API (1.5 Flash) for final answer

──────────────────────────────────────────────
🔍 MODULE OVERVIEW
──────────────────────────────────────────────
-  → CLI controller / menu
-  → pipeline: load → chunk → embed → store
-  → handles user query, retrieval, Gemini response
-  → all model names, chunk size, prompt templates
-  → Gemini API wrapper (with key from )
-  → HuggingFace embeddings logic
-  → vector store interface (Chroma)
-  → file type detection + parsing

──────────────────────────────────────────────
🔑 KEY TECH CONCEPTS
──────────────────────────────────────────────
- RAG (Retrieval-Augmented Generation): Enhances LLMs with private data
- LangChain: Framework for chaining AI components (loaders, splitters, retrievers)
- Vector DB (Chroma): Stores embedded text vectors for similarity-based retrieval
- HuggingFace Embeddings: SentenceTransformer models convert text → vector
- Gemini (Google Generative AI): Handles question answering using prompt + context

──────────────────────────────────────────────
⚠️ KEY DEBUG POINTS
──────────────────────────────────────────────
- Ollama LLMs caused port binding + hardware crashes (abandoned)
- Numpy 2.x incompatibility with sklearn/scipy → downgraded to 
- LangChain deprecated many imports → migrated to  + 

──────────────────────────────────────────────
📦 FINAL STATE
──────────────────────────────────────────────
- All modules refactored + isolated
- Works fully offline for ingestion
- Gemini API requires  with 
- CLI tested: ingestion, retrieval, multi-question flow
- Project frozen via 

──────────────────────────────────────────────

