# MOSDAC AI Help Bot

An AI-powered help bot for information retrieval from web content, specifically designed for the MOSDAC (Meteorological and Oceanographic Satellite Data Archival Centre) website.

## ğŸ¯ Project Overview

This project implements a comprehensive RAG (Retrieval-Augmented Generation) system that:
- **Scrapes** website content using intelligent crawling
- **Processes** and **indexes** content for optimal retrieval
- **Provides** natural language chat interface for information retrieval
- **Maintains** context and learns from interactions

## ğŸ“ Project Structure

### Core Files
```
privata/
â”œâ”€â”€ mosdac_bot.py          # ğŸ® Master control file - Main entry point
â”œâ”€â”€ main.py                # ğŸš€ Alternative entry point
â”œâ”€â”€ chat.py                # ğŸ’¬ Chat system implementation
â”œâ”€â”€ ingest.py              # ğŸ“¥ Data ingestion pipeline
â”œâ”€â”€ crawl4ai_mosdac.py     # ğŸ•·ï¸ Website crawler
â”œâ”€â”€ config.py              # âš™ï¸ Configuration management
â”œâ”€â”€ config.json            # ğŸ“‹ Configuration file
â””â”€â”€ requirements.txt       # ğŸ“¦ Dependencies
```

### Core Modules
```
models/
â””â”€â”€ llm_loader.py          # ğŸ¤– LLM integration

retriever/
â”œâ”€â”€ modern_vectordb.py     # ğŸ—„ï¸ Vector database operations
â”œâ”€â”€ multi_modal_embedder.py # ğŸ”¤ Text embedding
â””â”€â”€ reranker.py            # ğŸ¯ Result reranking

utils/
â”œâ”€â”€ enhanced_chunker.py    # âœ‚ï¸ Document chunking
â”œâ”€â”€ enhanced_doc_loader.py # ğŸ“„ Document loading
â””â”€â”€ structured_extractor.py # ğŸ” Data extraction
```

### Data Directory
```
crawl4ai_output_enhanced/  # ğŸ“Š Scraped website data
â”œâ”€â”€ home/                  # Individual page directories
â”œâ”€â”€ about-us/
â”œâ”€â”€ contact-us/
â””â”€â”€ crawling_summary.json  # Scraping statistics
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Run the Master Bot
```bash
python mosdac_bot.py
```

### 3. Choose Your Operation
- **Option 1**: Scrape data only
- **Option 2**: Ingest data only  
- **Option 3**: Complete workflow (scrape + ingest)
- **Option 4**: Chat with the bot
- **Option 5**: Check data status
- **Option 6**: Remove all data
- **Option 7**: Re-scrape and re-ingest
- **Option 8**: Exit

## ğŸ”§ Features

### ğŸ•·ï¸ Intelligent Web Crawling
- **Sitemap Discovery**: Automatically discovers all URLs from sitemap.xml
- **Structured Data Extraction**: Extracts tables, metadata, and structured content
- **Quality Scoring**: Rates content quality for better RAG performance
- **Parallel Processing**: Efficient concurrent crawling

### ğŸ“¥ Advanced Data Ingestion
- **Semantic Chunking**: Intelligent document segmentation
- **Multi-modal Embeddings**: Rich content representation
- **Deduplication**: Removes duplicate content
- **Quality Filtering**: Keeps only high-quality content

### ğŸ’¬ Smart Chat System
- **Context-Aware**: Maintains conversation context
- **Source Citations**: Provides source references
- **Reranking**: Optimizes result relevance
- **Natural Language**: Intuitive user interaction

### ğŸ—„ï¸ Vector Database
- **ChromaDB Integration**: Efficient similarity search
- **Persistent Storage**: Data survives restarts
- **Metadata Rich**: Comprehensive content indexing
- **Performance Optimized**: Fast retrieval

## âš™ï¸ Configuration

Edit `config.json` to customize:
- **Chunking parameters**: Size, overlap, strategy
- **Embedding model**: Text embedding configuration
- **Vector database**: Collection settings
- **Chat system**: Prompt templates and behavior

## ğŸ“Š Data Flow

1. **Crawling** â†’ Website content extraction
2. **Processing** â†’ Content cleaning and structuring
3. **Chunking** â†’ Semantic document segmentation
4. **Embedding** â†’ Vector representation creation
5. **Storage** â†’ Vector database indexing
6. **Retrieval** â†’ Similarity-based content search
7. **Generation** â†’ LLM-powered response creation

## ğŸ¯ Use Cases

- **Information Retrieval**: Find specific information quickly
- **FAQ System**: Answer common questions
- **Documentation Search**: Navigate complex documentation
- **Research Assistant**: Help with research tasks
- **Customer Support**: Provide automated support

## ğŸ” Technical Details

### RAG Pipeline
- **Retrieval**: Semantic similarity search
- **Augmentation**: Context enrichment
- **Generation**: LLM response creation

### Chunking Strategies
- **Semantic Similarity**: Content-based segmentation
- **Heading-Based**: Structure-aware splitting
- **Table Integrity**: Preserve table structure
- **Hybrid Approach**: Multiple strategies combined

### Embedding Models
- **Sentence Transformers**: High-quality text embeddings
- **Multi-modal**: Content, title, metadata integration
- **Context-Aware**: Relationship-aware representations

## ğŸš¨ Requirements

- Python 3.8+
- ChromaDB
- Sentence Transformers
- BeautifulSoup4
- LangChain
- Crawl4AI (for web crawling)

## ğŸ“ License

This project is part of the MOSDAC AI Help Bot system.

## ğŸ¤ Contributing

This is a specialized system for MOSDAC website content. For modifications or improvements, please refer to the project documentation.

---

**Note**: This system is optimized for the MOSDAC website structure but can be adapted for other websites by modifying the crawler configuration.