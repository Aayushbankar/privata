# MOSDAC AI Help Bot

An AI-powered help bot for information retrieval from the MOSDAC (Meteorological and Oceanographic Satellite Data Archival Center) website.

## ğŸš€ Quick Start

```bash
# Run the bot
./scripts/run_bot.sh

# Or manually
python main.py
```

## ğŸ“ Project Structure

```
privata/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ core/                     # Core functionality
â”‚   â”‚   â”œâ”€â”€ mosdac_bot.py        # Main bot controller
â”‚   â”‚   â”œâ”€â”€ config.py            # Configuration
â”‚   â”‚   â””â”€â”€ config.json          # Config file
â”‚   â”œâ”€â”€ scrapers/                 # Web scraping
â”‚   â”‚   â”œâ”€â”€ comprehensive_mosdac_scraper.py
â”‚   â”‚   â””â”€â”€ crawl4ai_mosdac.py
â”‚   â”œâ”€â”€ ingestion/                # Data ingestion
â”‚   â”‚   â””â”€â”€ ingest.py
â”‚   â”œâ”€â”€ chat/                     # Chat system
â”‚   â”‚   â””â”€â”€ chat.py
â”‚   â”œâ”€â”€ models/                   # LLM integration
â”‚   â”‚   â””â”€â”€ llm_loader.py
â”‚   â”œâ”€â”€ retrieval/                # Vector search & retrieval
â”‚   â”‚   â”œâ”€â”€ modern_vectordb.py
â”‚   â”‚   â”œâ”€â”€ multi_modal_embedder.py
â”‚   â”‚   â””â”€â”€ reranker.py
â”‚   â””â”€â”€ utils/                    # Utilities
â”‚       â”œâ”€â”€ enhanced_chunker.py
â”‚       â”œâ”€â”€ enhanced_doc_loader.py
â”‚       â””â”€â”€ structured_extractor.py
â”œâ”€â”€ data/                         # Data storage
â”‚   â”œâ”€â”€ scraped/                  # Scraped website data
â”‚   â”‚   â””â”€â”€ mosdac_complete_data/
â”‚   â””â”€â”€ vector_db/                # Vector database
â”‚       â””â”€â”€ chroma_db/
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ run_bot.sh               # Bot runner
â”‚   â”œâ”€â”€ setup_llm.py             # LLM setup helper
â”‚   â”œâ”€â”€ main.py                  # Legacy main
â”‚   â””â”€â”€ advanced_rag_ingestion.py
â”œâ”€â”€ tests/                        # Test files
â”‚   â”œâ”€â”€ test.py
â”‚   â””â”€â”€ test_chat.py
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ PROJECT_PROGRESS_REPORT.md
â”‚   â””â”€â”€ PROJECT_STATUS_REPORT.md
â”œâ”€â”€ main.py                       # Main entry point
â”œâ”€â”€ requirements.txt              # Dependencies
â””â”€â”€ README.md                     # This file
```

## ğŸ› ï¸ Features

- **Comprehensive Web Scraping**: 443 URLs processed (7x more than required)
- **RAG-Optimized Data Extraction**: 4.1M+ characters, 270 structured tables
- **Advanced Ingestion Pipeline**: 708 semantic chunks stored in ChromaDB
- **Fully Functional Chat System**: Natural language Q&A with citations
- **Dual LLM Support**: Gemini API + Ollama offline modes
- **Complete Data Management**: Status monitoring, removal, re-scraping

## ğŸ”§ Setup

1. **Install Dependencies**:
```bash
pip install -r requirements.txt
```

2. **Configure LLM**:
```bash
   # For API mode (recommended)
   export GEMINI_API_KEY="your-api-key"
   export LLM_MODE="api"
   
   # For Ollama mode (offline)
   export LLM_MODE="ollama"
   ```

3. **Run Setup Helper**:
```bash
   python scripts/setup_llm.py
```

## ğŸ¯ Usage

### Main Bot Interface
```bash
python main.py
```

### Direct Core Access
```bash
python src/core/mosdac_bot.py
```

### Test System
```bash
python tests/test_chat.py
```

## ğŸ“Š Current Status

- **Pages Scraped**: 443 URLs
- **Content Volume**: 4.1M+ characters
- **Vector Database**: 708 chunks indexed
- **Tables Extracted**: 270 structured tables
- **Quality Score**: 0.63 average

## ğŸ”„ Available Operations

1. **Scrape Data Only** - Extract all MOSDAC content
2. **Ingest Data Only** - Process scraped data into vector DB
3. **Scrape + Ingest** - Complete workflow
4. **Chat with Bot** - Interactive Q&A
5. **Check Data Status** - View system status
6. **Remove All Data** - Clean up data
7. **Re-scrape + Re-ingest** - Full refresh

## ğŸ¤– LLM Configuration

The bot supports two LLM modes:

### API Mode (Default)
- Uses Gemini API
- Faster, no local setup required
- Requires `GEMINI_API_KEY`

### Ollama Mode (Offline)
- Uses local Ollama installation
- Private, offline operation
- Requires Ollama server running

## ğŸ“ˆ Performance

- **Scraping**: 443 URLs in ~15 minutes
- **Ingestion**: 708 chunks in ~110 seconds
- **Retrieval**: Sub-second response times
- **Chat**: Real-time natural language responses

## ğŸ›¡ï¸ Quality Assurance

- **Source Citations**: Every response includes source references
- **Quality Scoring**: Automated content quality assessment
- **Session Management**: Context retention across conversations
- **Error Handling**: Graceful failure recovery

## ğŸ“ Documentation

- `docs/PROJECT_PROGRESS_REPORT.md` - Detailed development history
- `docs/PROJECT_STATUS_REPORT.md` - Current system status
- `scripts/setup_llm.py` - LLM configuration helper

## ğŸš€ Next Steps

1. **Continuous Crawling** - Automated updates
2. **Self-Learning** - Feedback collection and improvement
3. **Production Deployment** - Web interface and API
4. **Advanced Features** - Enhanced NLU and analytics

---

**Status**: Fully Functional âœ…  
**Last Updated**: September 13, 2025  
**Version**: 1.0
